# Khwarizmi

### What is this?
An FP8 implementation and a library to train neural networks using it. 

### Why?
To learn. And for the lulz. 

### What?
FP8 implementation using the ESM2 format. 1 bit for sign, 5 bits for the exponent, and 2 bits for the mantissa. Why? Does a better job of capturing exponent ranges, presumably required for Neural Networks. 

